{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 6. Задача lookalike (Positive Unlabeled Learning)\n",
    "\n",
    "### Домашнее задание\n",
    "\n",
    "1. взять любой набор данных для бинарной классификации (можно скачать один из модельных с https://archive.ics.uci.edu/ml/datasets.php)\n",
    "3. сделать feature engineering\n",
    "4. обучить любой классификатор (какой вам нравится)\n",
    "5. далее разделить ваш набор данных на два множества: P (positives) и U (unlabeled). Причем брать нужно не все положительные (класс 1) примеры, а только лишь часть\n",
    "6. применить random negative sampling для построения классификатора в новых условиях\n",
    "7. сравнить качество с решением из пункта 4 (построить отчет - таблицу метрик)\n",
    "8. поэкспериментировать с долей P на шаге 5 (как будет меняться качество модели при уменьшении/увеличении размера P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import catboost as catb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, precision_recall_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                  1       2           3   4                    5   \\\n",
       "0  39          State-gov   77516   Bachelors  13        Never-married   \n",
       "1  50   Self-emp-not-inc   83311   Bachelors  13   Married-civ-spouse   \n",
       "2  38            Private  215646     HS-grad   9             Divorced   \n",
       "\n",
       "                   6               7       8      9     10  11  12  \\\n",
       "0        Adm-clerical   Not-in-family   White   Male  2174   0  40   \n",
       "1     Exec-managerial         Husband   White   Male     0   0  13   \n",
       "2   Handlers-cleaners   Not-in-family   White   Male     0   0  40   \n",
       "\n",
       "               13      14  \n",
       "0   United-States   <=50K  \n",
       "1   United-States   <=50K  \n",
       "2   United-States   <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"adult.data\", header=None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: спрогнозировать, превышает ли доход 50 тысяч долларов в год.\n",
    "\n",
    "Посмотрим, есть ли пропуски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       32561 non-null  int64 \n",
      " 1   1       32561 non-null  object\n",
      " 2   2       32561 non-null  int64 \n",
      " 3   3       32561 non-null  object\n",
      " 4   4       32561 non-null  int64 \n",
      " 5   5       32561 non-null  object\n",
      " 6   6       32561 non-null  object\n",
      " 7   7       32561 non-null  object\n",
      " 8   8       32561 non-null  object\n",
      " 9   9       32561 non-null  object\n",
      " 10  10      32561 non-null  int64 \n",
      " 11  11      32561 non-null  int64 \n",
      " 12  12      32561 non-null  int64 \n",
      " 13  13      32561 non-null  object\n",
      " 14  14      32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет. Приведем таргет к числовому виду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "32556    0\n",
       "32557    1\n",
       "32558    0\n",
       "32559    0\n",
       "32560    1\n",
       "Name: 14, Length: 32561, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[14] = df[14].map({' <=50K': 0, ' >50K': 1}) \n",
    "df[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим соотношение таргета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24720\n",
       "1     7841\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[14].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим количество оригинальных значений у категориальных признаков (это нужно для определения параметра one_hot_max_size у catboost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 feauture has 9 unique values\n",
      "3 feauture has 16 unique values\n",
      "5 feauture has 7 unique values\n",
      "6 feauture has 15 unique values\n",
      "7 feauture has 6 unique values\n",
      "8 feauture has 5 unique values\n",
      "9 feauture has 2 unique values\n",
      "13 feauture has 42 unique values\n"
     ]
    }
   ],
   "source": [
    "cat_features = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "for i in cat_features:\n",
    "    print(f'{i} feauture has {pd.unique(df[i]).shape[0]} unique values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем разбиение на трейн и тест и обучим catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.618866, F-Score=0.737, Precision=0.689, Recall=0.793, ROC_AUC=0.931\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "X.drop(columns=14, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[14], test_size=0.3, shuffle=True, stratify=df[14], random_state=42)\n",
    "\n",
    "disbalance = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "cat_features = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "frozen_params = {\n",
    "     'class_weights':[1, disbalance], \n",
    "     'silent':True,\n",
    "     'random_state':42,\n",
    "     'cat_features':cat_features,\n",
    "     'one_hot_max_size':42\n",
    "}\n",
    "\n",
    "model = catb.CatBoostClassifier(**frozen_params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "fscore = (2 * precision[:-10] * recall[:-10]) / (precision[:-10] + recall[:-10])\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f, ROC_AUC=%.3f' % (thresholds[ix], \n",
    "                                                                                      fscore[ix],\n",
    "                                                                                      precision[ix],\n",
    "                                                                                      recall[ix],\n",
    "                                                                                     roc_auc_score(y_test, y_pred_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим Random Negative Sampling к нашему датасету. Причем долю положительных наблюдений будем варьировать от 0.1 до 0.9 от истинного количества положительного класса. После составим таблицу метрик в зависимости от доли положительных наблюдений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим словарь с метриками\n",
    "metric_dict = {\n",
    "    'P_sample_size': [],\n",
    "    'roc_auc': [],\n",
    "    'best_threshold': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1-score': []\n",
    "}\n",
    "\n",
    "np.random.seed(42)\n",
    "X = df.copy()\n",
    "X.drop(columns=14, inplace=True)\n",
    "y_true = df[14]\n",
    "# Создадим массив индексов с истинно положительным таргетом и перемешаем их:\n",
    "tp_index = np.array(y_true.loc[y_true==1].index)\n",
    "np.random.shuffle(tp_index)\n",
    "\n",
    "for i in np.linspace(.1, .9, 9):\n",
    "    \n",
    "    # Возьмем выборку положительных индексов для random negative sampling:\n",
    "    p_index = tp_index[:int(i*len(tp_index))]\n",
    "    # Создадим таргет для random negative sampling:\n",
    "    y_pu = pd.Series([0]*len(y_true))\n",
    "    y_pu.loc[p_index] = 1\n",
    "    # Извлечем выборку неразмеченных(Unlabeled) индексов и перемешаем их\n",
    "    u_index = np.array(y_true.loc[~y_true.index.isin(p_index)].index)\n",
    "    np.random.shuffle(u_index)\n",
    "    # Создадим тестовую выборку из неразмеченных, размером в треть от всего датасета\n",
    "    test_index = u_index[:int(0.3*len(y_true))]\n",
    "    # Сщздадим обучающую выборку из положительных и оставшейся части неразмеченных индексов:\n",
    "    train_index = np.concatenate((u_index[int(0.33*len(y_true)):], p_index))\n",
    "    # Создадим обучающие и валидационные наборы данных:\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_pu_train = y_pu.loc[train_index]\n",
    "    y_true_test = y_true.loc[test_index]\n",
    "\n",
    "    # Обучим модель catboost:\n",
    "    disbalance = y_pu_train.value_counts()[0] / y_pu_train.value_counts()[1]\n",
    "    cat_features = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "    frozen_params = {\n",
    "         'class_weights':[1, disbalance], \n",
    "         'silent':True,\n",
    "         'random_state':42,\n",
    "         'cat_features':cat_features,\n",
    "         'one_hot_max_size':42\n",
    "    }\n",
    "    model = catb.CatBoostClassifier(**frozen_params)\n",
    "    model.fit(X_train, y_pu_train)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_true_test, y_pred_proba)\n",
    "    fscore = (2 * precision[:-10] * recall[:-10]) / (precision[:-10] + recall[:-10])\n",
    "    ix = np.argmax(fscore)\n",
    "\n",
    "    # Внесем метрики в словарь метрик\n",
    "    metric_dict['P_sample_size'].append(i)\n",
    "    metric_dict['roc_auc'].append(roc_auc_score(y_true_test, y_pred_proba))\n",
    "    metric_dict['best_threshold'].append(thresholds[ix])\n",
    "    metric_dict['precision'].append(precision[ix])\n",
    "    metric_dict['recall'].append(recall[ix])\n",
    "    metric_dict['f1-score'].append(fscore[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_sample_size</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.857741</td>\n",
       "      <td>0.212283</td>\n",
       "      <td>0.492634</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.601439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.893348</td>\n",
       "      <td>0.508260</td>\n",
       "      <td>0.595361</td>\n",
       "      <td>0.695783</td>\n",
       "      <td>0.641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.563038</td>\n",
       "      <td>0.587573</td>\n",
       "      <td>0.683163</td>\n",
       "      <td>0.631773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.919618</td>\n",
       "      <td>0.592385</td>\n",
       "      <td>0.585433</td>\n",
       "      <td>0.703289</td>\n",
       "      <td>0.638972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.912939</td>\n",
       "      <td>0.620283</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.692982</td>\n",
       "      <td>0.614786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.921796</td>\n",
       "      <td>0.684284</td>\n",
       "      <td>0.564743</td>\n",
       "      <td>0.659381</td>\n",
       "      <td>0.608403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.915961</td>\n",
       "      <td>0.784293</td>\n",
       "      <td>0.635311</td>\n",
       "      <td>0.526379</td>\n",
       "      <td>0.575738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.924174</td>\n",
       "      <td>0.827817</td>\n",
       "      <td>0.612420</td>\n",
       "      <td>0.459069</td>\n",
       "      <td>0.524771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.933081</td>\n",
       "      <td>0.865393</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.471028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_sample_size   roc_auc  best_threshold  precision    recall  f1-score\n",
       "0            0.1  0.857741        0.212283   0.492634  0.771930  0.601439\n",
       "1            0.2  0.893348        0.508260   0.595361  0.695783  0.641667\n",
       "2            0.3  0.900461        0.563038   0.587573  0.683163  0.631773\n",
       "3            0.4  0.919618        0.592385   0.585433  0.703289  0.638972\n",
       "4            0.5  0.912939        0.620283   0.552448  0.692982  0.614786\n",
       "5            0.6  0.921796        0.684284   0.564743  0.659381  0.608403\n",
       "6            0.7  0.915961        0.784293   0.635311  0.526379  0.575738\n",
       "7            0.8  0.924174        0.827817   0.612420  0.459069  0.524771\n",
       "8            0.9  0.933081        0.865393   0.486486  0.456522  0.471028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNS_report = pd.DataFrame(metric_dict)\n",
    "RNS_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно по таблице, лучшими долями P_sample_size от общего количества положительных наблюдений по f1-score являются доли от 0.2 до 0.4. При этом метрика f1-score естественно ниже, чем при обычной классификации (там было 74%), так как при PU learning качество обучения модели падает из-за того, что в Unlabeled class находятся как positive так и negative наблюдения. Но между тем такой метод все равно позволяет нам найти похожие наблюдения, если брать наблюдения с максимальным predict_proba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
